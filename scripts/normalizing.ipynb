{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e71dc35b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07_29_25\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "from astropy.io import fits\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from astropy.io import ascii\n",
    "from astropy.table import Table\n",
    "\n",
    "plt.rcParams['figure.facecolor']    = 'white'\n",
    "import pandas as pd    \n",
    "from datetime import date\n",
    "today=date.today()\n",
    "DATE =today.strftime(\"%m_%d_%y\")\n",
    "print(DATE)\n",
    "import glob\n",
    "from astropy.coordinates import SkyCoord, EarthLocation\n",
    "import astropy.units as u\n",
    "\n",
    "vlt = EarthLocation.of_site('paranal')  # the easiest way... but requires internet\n",
    "\n",
    "\n",
    "# from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "992e165f",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_113 = glob.glob('../data/p113_data/*.fits')\n",
    "files_112 = glob.glob('../data/p112_data/*.fits')\n",
    "li_line = 6707.926\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0167ec9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4070051b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RG 20 C\n",
      "RG 13 C\n",
      "RG 14 C\n",
      "RG 1 C\n",
      "19\n",
      "10\n",
      "RG 12 C\n",
      "RG 6 C\n",
      "RG 3 C\n",
      "RG 11 C\n",
      "RG 22 C\n",
      "RG 15 C\n",
      "RG 3 C\n",
      "RG 8 C\n",
      "RG 3 C\n",
      "RG 25 C\n",
      "RG 8 C\n",
      "RG 22 C\n",
      "RG 3 C\n",
      "RG 7 C\n",
      "RG 23 C\n",
      "25\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "def get_files(files):\n",
    "    obj_dir = {}\n",
    "    c=3e5 #km/s\n",
    "\n",
    "    for i,file in enumerate(files):\n",
    "        with fits.open(file) as hdul:\n",
    "            hdul = fits.open(file)\n",
    "            header  = hdul[0].header\n",
    "            #print(header.cards['HIERARCH ESO QC CCF RV ERROR'])\n",
    "            data    = hdul[1].data\n",
    "            time    = header['HIERARCH ESO QC BJD']\n",
    "            name    = header['OBJECT']\n",
    "            obj     = int(header['HIERARCH ESO OBS NAME'].split('-')[0][2:])\n",
    "            grade   = header['OB_GRADE'].replace(\" \", \"\")\n",
    "            if grade =='C':\n",
    "                print('RG',obj,header['OB_GRADE'])\n",
    "                continue\n",
    "\n",
    "            ra,dec  = header['RA'], header['DEC']\n",
    "            obs_T   = header['DATE-OBS'].split('T')[0]\n",
    "            rv_val  =  header['HIERARCH ESO QC CCF RV']#header['HIERARCH ESO OCS OBJ RV'] #km/s\n",
    "            rv_err  = header['HIERARCH ESO QC CCF RV ERROR'] #km/s\n",
    "            sc = SkyCoord(ra=ra*u.deg, dec=dec*u.deg)\n",
    "            rv_corr = rv_val\n",
    "            err_corr = rv_err\n",
    "            if name=='UCAC4 308-077592':\n",
    "                if obj in obj_dir.keys():\n",
    "                    obj_dir[obj]['file'].append(file)\n",
    "                    obj_dir[obj]['rv'].append(rv_corr)\n",
    "                    obj_dir[obj]['time'].append(time)\n",
    "                    obj_dir[obj]['err'].append(err_corr)\n",
    "                    obj_dir[obj]['name'].append(name)\n",
    "                    obj_dir[obj]['grade'].append(grade)\n",
    "                else:\n",
    "                    obj_dir[obj] = {'file': [file], 'rv': [rv_corr], \n",
    "                                    'time': [time], 'err': [err_corr], \n",
    "                                    'name': [name], 'grade': [grade]}\n",
    "            else:\n",
    "                if rv_corr >= -100:\n",
    "                    if obj in obj_dir.keys():\n",
    "                        obj_dir[obj]['file'].append(file)\n",
    "                        obj_dir[obj]['rv'].append(rv_corr)\n",
    "                        obj_dir[obj]['time'].append(time)\n",
    "                        obj_dir[obj]['err'].append(err_corr)\n",
    "                        obj_dir[obj]['name'].append(name)\n",
    "                        obj_dir[obj]['grade'].append(grade)\n",
    "                    else:\n",
    "                        obj_dir[obj] = {'file': [file], 'rv': [rv_corr], \n",
    "                                        'time': [time], 'err': [err_corr], \n",
    "                                        'name': [name], 'grade': [grade]}\n",
    "    print(len(obj_dir.keys()))   \n",
    "    targets_to_remove = []\n",
    "    for k, v in obj_dir.items():\n",
    "        if len(v['time']) < 3:\n",
    "            targets_to_remove.append(k)\n",
    "    for i in range(len(targets_to_remove)):\n",
    "        del obj_dir[targets_to_remove[i]]\n",
    "    print(len(obj_dir.keys()))\n",
    "\n",
    "    myKeys = list(obj_dir.keys())\n",
    "    myKeys.sort()\n",
    "    obj_dir = {i: obj_dir[i] for i in myKeys}\n",
    "    return obj_dir\n",
    "obj_dir_112 = get_files(files_112)\n",
    "obj_dir_113 = get_files(files_113)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a38358",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05b0569c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rv_correct(rg, obj_dir, lower_wave, plot=False):\n",
    "    c = 3e5 #km/s\n",
    "    files = obj_dir[rg]['file']\n",
    "    rvs    = obj_dir[rg]['rv']\n",
    "    plt.figure(figsize=(15,10))\n",
    "\n",
    "    all_flux = []\n",
    "    all_wave = []\n",
    "    all_ferr = [] #flux_err\n",
    "    for i,file in enumerate(files):\n",
    "        with fits.open(file) as hdul:\n",
    "            hdul = fits.open(file)\n",
    "            header = hdul[0].header\n",
    "            data  = hdul[1].data\n",
    "            rv_val  =  header['HIERARCH ESO QC CCF RV']#header['HIERARCH ESO OCS OBJ RV'] #km/s\n",
    "            wave, flux = data['WAVE_AIR'][0], data['FLUX    '][0]\n",
    "            flux_err   = data['ERR'][0]\n",
    "            mask       = (wave > lower_wave)\n",
    "            wave, flux = wave[mask], flux[mask]\n",
    "            flux_err   = flux_err[mask]\n",
    "            plt.subplot(len(files),1,i+1)\n",
    "            plt.plot(wave, flux, lw=0.5)\n",
    "            plt.axvline(li_line,c='C1')\n",
    "            plt.xlim(6700, 6717)\n",
    "            mask = (wave >= 6708) & (wave <= 6710)\n",
    "            new_wave = wave[mask]\n",
    "            new_flux = flux[mask]\n",
    "            w0 = li_line*1\n",
    "            w1 = new_wave[np.argmin(new_flux)]\n",
    "            shift = (rv_val/c)*(w0)\n",
    "            #print((w1 - w0)*c/w0, rv_val, shift)\n",
    "            plt.plot(wave-shift, flux)\n",
    "            \n",
    "            corrected_wave = wave-shift\n",
    "            all_wave.append(corrected_wave)\n",
    "            all_flux.append(flux)\n",
    "            all_ferr.append(flux_err)      \n",
    "    plt.tight_layout()\n",
    "    if not plot: plt.close()\n",
    "    return all_wave, all_flux, all_ferr\n",
    "    \n",
    "_,_,_ = rv_correct(1, obj_dir_112, lower_wave=4500.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b55fb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interp_wave(w, f, fe):\n",
    "    '''\n",
    "    interpolate all the wavelength to same grid for target spectrum\n",
    "    @input:\n",
    "        w : original wavelength grid of each observation after RV correction\n",
    "        f : flux values of each observation\n",
    "    '''\n",
    "    \n",
    "    wave_grid = w[0]\n",
    "\n",
    "    all_flux = []\n",
    "    all_flux.append(f[0])\n",
    "    \n",
    "    all_ferr = []\n",
    "    all_ferr.append(fe[0])\n",
    "    \n",
    "    for i in range(1,len(w)):\n",
    "        target_wave, target_flux, target_ferr = w[i],f[i],fe[i]\n",
    "        target_flux_interp = np.interp(wave_grid, target_wave, target_flux)\n",
    "        target_ferr_interp = np.interp(wave_grid, target_wave, target_ferr)\n",
    "        all_flux.append(target_flux_interp)\n",
    "        all_ferr.append(target_ferr_interp)\n",
    "       \n",
    "    return wave_grid, all_flux, all_ferr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e87ca58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack(all_flux,plot=False):\n",
    "    stacked = np.sum(np.array(all_flux), axis=0)\n",
    "    if plot:# plot stacked spectra\n",
    "        plt.figure(figsize=(10,4))\n",
    "\n",
    "        for spectrum in all_flux:\n",
    "            plt.plot(w,spectrum)\n",
    "\n",
    "        plt.plot(w,stacked,label='stacked')\n",
    "        plt.legend()\n",
    "        plt.xlim(6550,6570)\n",
    "        plt.ylim(0,0.4e-12)\n",
    "\n",
    "        plt.tight_layout()\n",
    "    return stacked\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34a710f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "table4 = pd.read_csv('table4.csv')\n",
    "rv_df = pd.read_csv('comb_rvs.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f39d0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "import corner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74e0b185",
   "metadata": {},
   "outputs": [],
   "source": [
    "import thejoker as tj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92f77306",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up(df):\n",
    "    time = df['comb_time']\n",
    "    rv = df['comb_rv']\n",
    "    err = df['comb_rv_err']\n",
    "    \n",
    "    time = time.values[0].split('[')[-1].split(']')[0].split(' ')#[:-1]\n",
    "    time = [t for t in time if len(t) > 0]\n",
    "    time = [float(t.split('\\n')[0].replace(\"'\",\"\")) for t in time]\n",
    "    \n",
    "    rv = rv.values[0].split('[')[-1].split(']')[0].split(' ')#[:-1]\n",
    "    rv = [t for t in rv if len(t) > 0]\n",
    "    rv = [float(t.split('\\n')[0]) for t in rv]\n",
    "    \n",
    "    err = err.values[0].split('[')[-1].split(']')[0].split(' ')#[:-1]\n",
    "    err = [t for t in err if len(t) > 0]\n",
    "    err = [float(t.split('\\n')[0]) for t in err]\n",
    "    \n",
    "    return time, rv, err\n",
    "from astropy.time import Time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7f03379",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_list_113 = 1, 4, 5, 7, 9, 11, 16, 18, 19, 21, 23  \n",
    "binary_list_112 = 5, 6, 7, 23 #13 removed because of dipper star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "997f354e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.9/site-packages/xarray/core/concat.py:527: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  common_dims = tuple(pd.unique([d for v in vars for d in v.dims]))\n",
      "WARNING:root:Pandas support in corner is deprecated; use ArviZ directly\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120.3849952918936 120.3849952918936\n",
      "0.5340017114391723 0.5340017114391723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.9/site-packages/xarray/core/concat.py:527: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  common_dims = tuple(pd.unique([d for v in vars for d in v.dims]))\n",
      "WARNING:root:Pandas support in corner is deprecated; use ArviZ directly\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "645.7894263564455 645.7894263564455\n",
      "0.20428795495181412 0.2042879549518141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.9/site-packages/xarray/core/concat.py:527: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  common_dims = tuple(pd.unique([d for v in vars for d in v.dims]))\n",
      "WARNING:root:Pandas support in corner is deprecated; use ArviZ directly\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.67748519568736 19.67748519568736\n",
      "0.245722536607039 0.245722536607039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.9/site-packages/xarray/core/concat.py:527: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  common_dims = tuple(pd.unique([d for v in vars for d in v.dims]))\n",
      "WARNING:root:Pandas support in corner is deprecated; use ArviZ directly\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122.55974178465516 122.55974178465516\n",
      "0.36402550806885253 0.3640255080688525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.9/site-packages/xarray/core/concat.py:527: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  common_dims = tuple(pd.unique([d for v in vars for d in v.dims]))\n",
      "WARNING:root:Pandas support in corner is deprecated; use ArviZ directly\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.62099356684482 34.62099356684482\n",
      "0.06545599588983117 0.0654559958898311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.9/site-packages/xarray/core/concat.py:527: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  common_dims = tuple(pd.unique([d for v in vars for d in v.dims]))\n",
      "WARNING:root:Pandas support in corner is deprecated; use ArviZ directly\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.415055240795297 21.415055240795297\n",
      "0.17335658813535731 0.1733565881353573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.9/site-packages/xarray/core/concat.py:527: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  common_dims = tuple(pd.unique([d for v in vars for d in v.dims]))\n",
      "WARNING:root:Pandas support in corner is deprecated; use ArviZ directly\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.852943982871354 8.852943982871354\n",
      "0.7238086580751097 0.7238086580751097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.9/site-packages/xarray/core/concat.py:527: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  common_dims = tuple(pd.unique([d for v in vars for d in v.dims]))\n",
      "WARNING:root:Pandas support in corner is deprecated; use ArviZ directly\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.72471131602055 95.72471131602056\n",
      "0.9972057775774968 0.9972057775774968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.9/site-packages/xarray/core/concat.py:527: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  common_dims = tuple(pd.unique([d for v in vars for d in v.dims]))\n",
      "WARNING:root:Pandas support in corner is deprecated; use ArviZ directly\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.001598134894756 54.00159813489476\n",
      "0.35337282909239587 0.3533728290923958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.9/site-packages/xarray/core/concat.py:527: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  common_dims = tuple(pd.unique([d for v in vars for d in v.dims]))\n",
      "WARNING:root:Pandas support in corner is deprecated; use ArviZ directly\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.00826535070272 9.00826535070272\n",
      "0.13814549500078532 0.1381454950007853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.9/site-packages/xarray/core/concat.py:527: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  common_dims = tuple(pd.unique([d for v in vars for d in v.dims]))\n",
      "WARNING:root:Pandas support in corner is deprecated; use ArviZ directly\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1525.6113977197238 1525.6113977197238\n",
      "0.9289160630758646 0.9289160630758646\n"
     ]
    }
   ],
   "source": [
    "import pickle \n",
    "\n",
    "program = 113\n",
    "version = 1\n",
    "\n",
    "for RG in binary_list_113:\n",
    "    fname = '../mcmc/%s_%s_mcmc_%s.pickle'%(program,RG,version)\n",
    "\n",
    "    with open(fname, 'rb') as handle:\n",
    "        mcmc_samples = pickle.load(handle)\n",
    "    fname2 = '../mcmc/%s_%s_trace_%s.pickle'%(program,RG,version)\n",
    "    with open(fname2, 'rb') as handle:\n",
    "        trace = pickle.load(handle)\n",
    "    fname3   = '../mcmc/%s_%s_joker_%s.hdf5'%(program,RG,version)\n",
    "\n",
    "    Ps = mcmc_samples['P'].value\n",
    "    es = mcmc_samples['e'].value\n",
    "    Ks = mcmc_samples['K'].value\n",
    "    try:\n",
    "        print(np.percentile(Ps, 50),table4[(table4.program==program) & (table4.RG_id==RG)]['P50'].values[0])\n",
    "        print(np.percentile(es, 50),table4[(table4.program==program) & (table4.RG_id==RG)]['e50'].values[0])\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    colnames = ['P','e','K','v0']\n",
    "    summary = az.summary(trace, colnames)\n",
    "    rhat = summary['r_hat'].to_list() \n",
    "\n",
    "    fig = corner.corner(mcmc_samples.tbl.to_pandas()[colnames], \n",
    "                        labels=[\n",
    "                            r\"$P$\", r\"$e$\", r\"$K$\",r\"$v_0$\"],\n",
    "                        quantiles=[0.16, 0.5, 0.84],\n",
    "                        show_titles=True,\n",
    "                        title_kwargs={\"fontsize\": 12}\n",
    "                       )\n",
    "\n",
    "    # Save the combined plot to a new PNG file\n",
    "    plt.savefig('final_corner_plots/0_%s_%s.png'%(program, RG), bbox_inches='tight',dpi=200)\n",
    "    plt.close()\n",
    "    \n",
    "    dft = table4[(table4.program==program) & (table4.RG_id==RG)]\n",
    "    joker_samples = tj.JokerSamples.read(fname3)\n",
    "    time, rv, rv_err = clean_up(dft)\n",
    "    plt.figure(figsize=(10,4))\n",
    "    from utils import PLOT_PARAMS\n",
    "    PLOT_PARAMS()\n",
    "    ax=plt.subplot(111)\n",
    "    data = Table()\n",
    "    data['bjd']     = time\n",
    "    data['rv']      = rv\n",
    "    data['rv_err']  = rv_err\n",
    "    data[\"rv\"].unit = u.km / u.s\n",
    "    data[\"rv_err\"].unit = u.km / u.s\n",
    "\n",
    "    data = tj.RVData(\n",
    "        t=Time(data[\"bjd\"], format=\"jd\", scale=\"tcb\"),\n",
    "        rv=u.Quantity(data[\"rv\"]),\n",
    "        rv_err=u.Quantity(data[\"rv_err\"]))\n",
    "\n",
    "    _ = tj.plot_rv_curves(joker_samples, data=data, ax=ax)\n",
    "    plt.savefig('final_corner_plots/1_%s_%s.png'%(program, RG), bbox_inches='tight',dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "    from PIL import Image\n",
    "    # Load the PNG images\n",
    "    image1 = Image.open('final_corner_plots/0_%s_%s.png'%(program, RG))  # Replace 'image1.png' with your first image file\n",
    "    image2 = Image.open('final_corner_plots/1_%s_%s.png'%(program, RG))  # Replace 'image2.png' with your second image file\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5)) # Adjust figsize as needed\n",
    "\n",
    "    axes[0].imshow(image1)\n",
    "    axes[0].axis('off')  # Hide axes ticks and labels\n",
    "\n",
    "    # Display the second image in the second subplot\n",
    "    axes[1].imshow(image2)\n",
    "    axes[1].axis('off')  # Hide axes ticks and labels\n",
    "\n",
    "    # Adjust layout to prevent overlap\n",
    "    fig.suptitle('%s - %s'%(program, RG),fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.savefig('final_corner_plots/%s_%s.png'%(program, RG), bbox_inches='tight',dpi=200)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06b43a02",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-09dbdbc7f6cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ss' is not defined"
     ]
    }
   ],
   "source": [
    "ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d030e409",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c51bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b248fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.percentile(Ps, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21d638f",
   "metadata": {},
   "outputs": [],
   "source": [
    "table4[(table4.program==112) & (table4.RG_id==23)][['P50','e50']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ffa752",
   "metadata": {},
   "outputs": [],
   "source": [
    "table4[(table4.program==113) & (table4.RG_id==16)][['P50','e50']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e778d119",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_template(RG, program):\n",
    "    \n",
    "    table4 = pd.read_csv('table4.csv')\n",
    "    rv_df = pd.read_csv('comb_rvs.csv')\n",
    "    vbroad = rv_df[(rv_df.program==program) & (rv_df.RG_id==RG)].vbroad.values[0]\n",
    "\n",
    "    templates = glob.glob('../files/Arcturus_templates/arcturus_*.txt')\n",
    "    fname = '../files/Arcturus_templates/arcturus_vsini_%s.txt'%vbroad\n",
    "    \n",
    "    print(vbroad, fname)    \n",
    "    \n",
    "    template_og = pd.read_csv(fname,delimiter=' ')\n",
    "    return template_og\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fec8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interp_template(wave_grid, template,plot=False):\n",
    "    \n",
    "    min_wave_esp, max_wave_esp = min(wave_grid), max(wave_grid)\n",
    "    \n",
    "    template = template[(template.waveobs <= max_wave_esp) & (template.waveobs >= min_wave_esp)]\n",
    "    temp_wave = np.array(template.waveobs)\n",
    "    temp_flux = np.array(template.flux)\n",
    "    temp_flux_interp = np.interp(wave_grid, temp_wave, temp_flux)\n",
    "\n",
    "    print('N points in target spectrum:',len(wave_grid))\n",
    "    print('N points in template spectrum:',len(temp_wave))\n",
    "    if plot:\n",
    "        plt.figure(figsize=(10,4),dpi=200)\n",
    "\n",
    "        plt.plot(temp_wave, temp_flux, label='OG template')\n",
    "        plt.plot(wave_grid, temp_flux_interp, label='interpolate template')\n",
    "        plt.xlim(6550,6570)\n",
    "        plt.ylim(0.5,1.1)\n",
    "    return temp_flux_interp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59cba7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_cont(wave, flux, percentage=5):\n",
    "    '''\n",
    "    identify continuum\n",
    "    percentage of spectra to mask out; default is 5%\n",
    "    '''\n",
    "    percentage /= 100\n",
    "    lower, upper = 1-percentage,1+percentage,\n",
    "    mask = (flux<=upper) & (flux>=lower)\n",
    "    return mask\n",
    "    \n",
    "def fit_cont(wave, flux, order=3):\n",
    "    '''\n",
    "    fit the continuum with polynomial\n",
    "    '''\n",
    "    coefficients  = np.polyfit(wave, flux, order) # Fit a n-order polynomial\n",
    "    poly_function = np.poly1d(coefficients)\n",
    "    fitted_flux   = poly_function(wave)\n",
    "    return poly_function\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2038e0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.facecolor'] = 'white'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d15a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d3f68d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128fed06",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def pipeline(RG, obj_dir, program, lower_wave, percentage=5, close=False, savefig=False, savetxt=False):\n",
    "    \n",
    "    # load RV corrected spectra\n",
    "    wave, flux, ferr      = rv_correct(RG, obj_dir, lower_wave)\n",
    "    \n",
    "    # interpolate RV corrected spectra onto one grid\n",
    "    wave_grid, flux, ferr = interp_wave(wave, flux, ferr)\n",
    "    \n",
    "    # stack all target spectrum\n",
    "    stacked_flux     = stack(flux,plot=False)\n",
    "    avg_ferr         = np.mean(ferr, axis=0)\n",
    "    \n",
    "    target_flux      = stacked_flux*1\n",
    "\n",
    "    # load template based on each target's vbroad\n",
    "    template         = load_template(RG, program)\n",
    "    \n",
    "    # interpolate the template onto target spectrum grid\n",
    "    temp_flux_interp = interp_template(wave_grid, template)           \n",
    "    \n",
    "    # identify the continuum in the template\n",
    "    cont_mask        = id_cont(wave_grid, temp_flux_interp, percentage) \n",
    "    \n",
    "#     plt.figure(figsize=(10,4),dpi=200)\n",
    "#     plt.plot(wave_grid, temp_flux_interp)\n",
    "#     plt.plot(wave_grid[cont_mask], temp_flux_interp[cont_mask])\n",
    "#     plt.xlim(6550,6570)\n",
    "    if close: plt.close()\n",
    "\n",
    "    # mask out the continuum indices in the target spectrum\n",
    "    cont_wave, cont_flux = wave_grid[cont_mask], target_flux[cont_mask]\n",
    "    \n",
    "    fig = plt.figure(figsize=(10,6),dpi=200)\n",
    "    ax1 = plt.subplot(211)\n",
    "    plt.plot(wave_grid, target_flux, label='target flux (unnormalized)')\n",
    "#     plt.plot(cont_wave, cont_flux, label='continuum identified (unnormalized)')\n",
    "#     plt.show()\n",
    "#     plt.xlim(6550,6570)\n",
    "    \n",
    "    # fit a polynomial to the continuum in the target spectrum\n",
    "    poly_func = fit_cont(cont_wave, cont_flux)\n",
    "    plt.plot(wave_grid, poly_func(wave_grid) , label='Fit')\n",
    "    plt.legend()\n",
    "    # divide the original target flux values by the function\n",
    "    target_flux_norm = stacked_flux/poly_func(wave_grid) \n",
    "    \n",
    "    \n",
    "    ax2 = plt.subplot(212)\n",
    "    plt.plot(wave_grid, target_flux_norm, label='Normalized target spectrum')\n",
    "    plt.plot(wave_grid, temp_flux_interp, label='Arcturus template interpolated')\n",
    "    plt.xlabel('Wavelength [A]')\n",
    "    plt.ylabel('Normalized Flux')\n",
    "    plt.legend()\n",
    "    \n",
    "#     ax3 = plt.subplot(413)\n",
    "#     plt.plot(wave_grid, target_flux_norm, label='Normalized target spectrum')\n",
    "#     plt.plot(wave_grid, temp_flux_interp, label='Arcturus template interpolated')\n",
    "#     plt.legend()\n",
    "#     plt.title('H-alpha line')\n",
    "#     plt.xlim(6550,6570)\n",
    "#     plt.ylim(0.,1.2)\n",
    "    \n",
    "#     ax4 = plt.subplot(414)\n",
    "#     plt.plot(wave_grid, target_flux_norm, label='Normalized target spectrum')\n",
    "#     plt.plot(wave_grid, temp_flux_interp, label='Arcturus template interpolated')\n",
    "#     plt.legend()\n",
    "#     plt.title('Li line')\n",
    "#     plt.xlim(6700, 6710)\n",
    "#     plt.ylim(0.,1.2)\n",
    "\n",
    "    rv_df = pd.read_csv('comb_rvs.csv')\n",
    "    rv_df = rv_df[(rv_df.program==program) & (rv_df.RG_id==RG)]\n",
    "    Li_val = rv_df.Li_val.values[0]\n",
    "    vbroad = rv_df.vbroad.values[0]\n",
    "    \n",
    "    title = 'P%s RG%s:    Li = %.1f    vbroad = %.1f' % (program, RG, Li_val, vbroad)\n",
    "    ax1.set_title(title)\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     if savefig: plt.savefig('../files/normalized_spectra_png/%s_%s.png'%(program, RG),bbox_inches='tight',dpi=200)\n",
    "#     if close: plt.close()\n",
    "    \n",
    "#     print(len(wave_grid),len(ferr))\n",
    "    \n",
    "#     spectrum = np.array([wave_grid, target_flux_norm, avg_ferr]).T\n",
    "#     savedir  = '../files/normalized_spectra_txt/'\n",
    "#     fname    = savedir+'%s_%s.txt'%(program, RG)\n",
    "#     print(fname)\n",
    "    hbeta_line = 4861.363\n",
    "    ax2.axvline(hbeta_line)\n",
    "    ax2.set_xlim(hbeta_line-5,hbeta_line+5)\n",
    "\n",
    "#     if savetxt: np.savetxt(fname,spectrum)\n",
    "    plt.savefig('../plots/check_cosmic_rays/%s_%s.png'%(program, RG),bbox_inches='tight',dpi=200)\n",
    "\n",
    "# for i,RG in enumerate(obj_dir_112.keys()):\n",
    "#     pipeline(RG,obj_dir_112,112,lower_wave=4500.,close=False,savefig=False,savetxt=False)\n",
    "         \n",
    "# pipeline(23,obj_dir_112,112,lower_wave=4500.,close=False,savefig=False,savetxt=False)\n",
    "pipeline(5,obj_dir_113,113,lower_wave=4500.,close=False,savefig=False,savetxt=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bad9869",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.stats import mad_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb6919b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def remove_cosmic_rays(RG, obj_dir, program, N, lower_wave=4500.):\n",
    "    # load RV corrected spectra\n",
    "    wave, flux, ferr      = rv_correct(RG, obj_dir, lower_wave)\n",
    "    \n",
    "    # interpolate RV corrected spectra onto one grid\n",
    "    wave_grid, flux, ferr = interp_wave(wave, flux, ferr)\n",
    "    \n",
    "    # stack all target spectrum\n",
    "    stacked_flux     = stack(flux,plot=False)\n",
    "    avg_ferr         = np.mean(ferr, axis=0)\n",
    "    \n",
    "    target_flux      = stacked_flux*1\n",
    "    plt.figure(figsize=(12,4),dpi=100)\n",
    "    \n",
    "    \n",
    "    i1 = 4500.\n",
    "    dw = 500.\n",
    "    lims = np.arange(i1, 8000.+dw, dw)\n",
    "#     lims = lims[4:6]\n",
    "    plt.plot(wave_grid, target_flux,c='C0',lw=1,zorder=-100)\n",
    "#     plt.scatter(wave_grid, target_flux,s=5)\n",
    "    \n",
    "#     for i in range(len(lims)-1):\n",
    "#         plt.figure(figsize=(12,4),dpi=100)\n",
    "#         plt.subplot(121)\n",
    "#         \n",
    "        \n",
    "#         sec_wave, sec_flux = wave_grid[mask], target_flux[mask]\n",
    "#         plt.plot(sec_wave, sec_flux,lw=1)\n",
    "#         med_flux = np.median(sec_flux)\n",
    "#         plt.axhline(med_flux,c='C%s'%i)\n",
    "#         std  = mad_std(sec_flux)\n",
    "#         mask = (sec_flux - med_flux)<=(3.*std)\n",
    "#         keep_wave, keep_flux = sec_wave[mask], sec_flux[mask]\n",
    "\n",
    "#         plt.plot(keep_wave, keep_flux,lw=1)\n",
    "# #         plt.xlim(6500,6600)\n",
    "#         plt.subplot(122)\n",
    "#         plt.hist(sec_flux,bins='auto')\n",
    "#         plt.axvline(np.median(sec_flux),c='r')\n",
    "#     plt.show()\n",
    "    \n",
    "    \n",
    "    lower, upper = 5500,6000\n",
    "    print(lower, upper)\n",
    "    mask = (wave_grid<=upper) & (wave_grid>lower)\n",
    "    sec_wave, sec_flux = wave_grid[mask], target_flux[mask]\n",
    "    \n",
    "    top_5_indices = np.argsort(target_flux[mask])[::-1][:N]\n",
    "    xx = []\n",
    "#     for i in top_5_indices:\n",
    "        \n",
    "#         idx = np.where(wave_grid==sec_wave[i])[0]\n",
    "#         plt.scatter(wave_grid[idx], target_flux[idx],c='k',zorder=100)\n",
    "#         xx.append(idx[0])\n",
    "    print(xx)\n",
    "#     plt.plot(wave_grid[mask], target_flux[mask],lw=1)      \n",
    "#     idx = np.argmax(target_flux[mask])\n",
    "    \n",
    "#     plt.scatter(wave_grid[mask][idx], target_flux[mask][idx],c='r')\n",
    "#     print(idx,len(wave_grid),len(wave_grid[mask]))\n",
    "#     plt.scatter(wave_grid[mask][idx], target_flux[mask][idx],c='r')\n",
    "#     print(wave_grid[mask][idx])\n",
    "    \n",
    "#     idx = np.where(wave_grid==wave_grid[mask][idx])[0]\n",
    "#     plt.scatter(wave_grid[idx], target_flux[idx],c='k',zorder=100)\n",
    "#     print(idx)\n",
    "    \n",
    "#     plt.xlim(lower,upper)\n",
    "    plt.show()\n",
    "\n",
    "# indices = np.arange(0,len(wave_grid),1)\n",
    "# indices = [i for i in indices if i not in [147187, 216836,308174]]\n",
    "# wave_grid, target_flux = wave_grid[indices], target_flux[indices]\n",
    "\n",
    "d={1:[147187, 216836,308174], \n",
    "   2:[116788, 100939, 116787, 106176, 111459, 95748],\n",
    "   3:[] ,\n",
    "   4:[143804, 158902, 162978,215307],\n",
    "   5:[38007,169478, 147545, 161014,175336, 184484],\n",
    "   6:[] ,\n",
    "   7:[171914, 160987,263423, 243341, 243337] ,\n",
    "   8:[172392],\n",
    "   9:[244301],\n",
    "   12:[99390,162053, 141067]\n",
    "  }\n",
    "remove_cosmic_rays(5,obj_dir_113,113, N=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7fbeb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "galah_linelist = Table.read('galah_linelist.csv').to_pandas() # in air\n",
    "galah_linelist['wl'] = galah_linelist['wl']*1e8   # in angstroms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d07ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "galah_linelist[galah_linelist['species']=='Ba I'].sort_values(by=['log_gf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bab4e1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "galah_linelist[galah_linelist['species']=='Ba I'].sort_values(by=['log_gf'])\n",
    "# # galah_linelist.dtypes\n",
    "galah_lines = ascii.read('../files/galah_dr3_lines.txt',delimiter='&').to_pandas() #https://github.com/svenbuder/GALAH_DR3/blob/master/validation/abundances/GALAH_DR3_abundances_lines.tex from \n",
    "galah_lines[galah_lines.element=='Li1']\n",
    "# galah_lines.element\n",
    "# galah_lines.keys()\n",
    "# galah_lines.element.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ff49d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "galah_lines[galah_lines.element=='Ce2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6176e34",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_lines(program, RG):\n",
    "    savedir  = '../files/normalized_spectra_txt/'\n",
    "    \n",
    "    fname    = savedir+'%s_%s.txt'%(program, RG)\n",
    "    data     = np.loadtxt(fname)\n",
    "    esp_wave = data[:,0]\n",
    "    esp_flux = data[:,1]\n",
    "    esp_err  = data[:,2]\n",
    "    print(min(esp_wave))\n",
    "    \n",
    "    plt.figure(figsize=(10,15))\n",
    "#     plt.plot(esp_wave, esp_flux)\n",
    "    elements = galah_lines.element.unique()\n",
    "    elements = ['Li1' ,'Y 2' ,'Zr1','Ba2' ,'La2']\n",
    "\n",
    "    c=0\n",
    "    for i,e in enumerate(elements):\n",
    "        \n",
    "        temp = galah_lines[galah_lines.element==e]\n",
    "        #print(temp['wave'])\n",
    "        print(e,len(temp))\n",
    "        if len(temp) == 1:\n",
    "            wave = temp['wave'][0]\n",
    "            mask = temp['mask'][0]\n",
    "            lower, upper = mask.split('-')\n",
    "            lower, upper = float(lower),float(upper)\n",
    "            \n",
    "            # PLOT\n",
    "            ax=plt.subplot(7,3,c+1)\n",
    "            plt.plot(esp_wave, esp_flux)\n",
    "            plt.axvline(wave,c='r',lw=1)\n",
    "            plt.axvspan(lower, upper, color='green',alpha=0.2)\n",
    "            plt.xlim(wave-5,wave+5)\n",
    "            plt.ylim(0,1.4)\n",
    "            ax.text(0.03, 0.03, s='%s-%.2f'%(e[:-1],wave), transform=ax.transAxes, ha='left',va='bottom')\n",
    "            c+=1\n",
    "        else:\n",
    "\n",
    "            for j,row in temp.iterrows():\n",
    "                ax = plt.subplot(7,3,c+1)\n",
    "                wave = row['wave']\n",
    "                mask = row['mask']\n",
    "                \n",
    "                lower, upper = mask.split('-')\n",
    "                lower, upper = float(lower),float(upper)\n",
    "                # PLOT\n",
    "                ax=plt.subplot(7,3,c+1)\n",
    "                plt.plot(esp_wave, esp_flux)\n",
    "                plt.axvline(wave,c='r',lw=1)\n",
    "                plt.axvspan(lower, upper, color='green',alpha=0.2)\n",
    "                plt.xlim(wave-5,wave+5)\n",
    "                plt.ylim(0,1.4)\n",
    "                ax.text(0.03, 0.03, s='%s-%.2f'%(e[:-1],wave), transform=ax.transAxes, ha='left',va='bottom')\n",
    "\n",
    "                c+=1\n",
    "    plt.show()\n",
    "                \n",
    "plot_lines(113,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c33baa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# galah_linelist[galah_linelist['species']=='Ba I'].sort_values(by=['log_gf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aca0889",
   "metadata": {},
   "outputs": [],
   "source": [
    "rv_df = pd.read_csv('comb_rvs.csv')\n",
    "rv_df.sobject_id.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715c3690",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def compare_to_galah(program, RG):\n",
    "    savedir  = '../files/normalized_spectra_txt/'\n",
    "    \n",
    "    fname    = savedir+'%s_%s.txt'%(program, RG)\n",
    "    data     = np.loadtxt(fname)\n",
    "    esp_wave = data[:,0]\n",
    "    esp_flux = data[:,1]\n",
    "    esp_err  = data[:,2]\n",
    "    \n",
    "    # load template based on each target's vbroad\n",
    "    template         = load_template(RG, program)\n",
    "    \n",
    "    # interpolate the template onto target spectrum grid\n",
    "    temp_flux_interp = interp_template(esp_wave, template)\n",
    "\n",
    "#     table4   = pd.read_csv('table4.csv')\n",
    "    rv_df    = pd.read_csv('comb_rvs.csv')\n",
    "    \n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2,2,figsize=(12,5),dpi=200)\n",
    "    \n",
    "    for ax in [ax1,ax2,ax3,ax4]:\n",
    "        ax.plot(esp_wave, esp_flux, c='C0',label='ESPRESSO',lw=1)\n",
    "        ax.plot(esp_wave, temp_flux_interp, c='k',label='Template',lw=1)\n",
    "\n",
    "    rv_df = rv_df[(rv_df.program==program) & (rv_df.RG_id==RG)]\n",
    "    sobject_id = rv_df.sobject_id.values[0]\n",
    "\n",
    "    dirname = '../files/galah_spectra/'\n",
    "    for ccd in [1,2,3,4]:\n",
    "        fname   = dirname+'%s%s.fits'% (sobject_id, ccd)\n",
    "        ff      = fits.open(fname)\n",
    "        start_wavelength = ff[4].header[\"CRVAL1\"]\n",
    "        dispersion       = ff[4].header[\"CDELT1\"]\n",
    "        nr_pixels        = ff[4].header[\"NAXIS1\"]\n",
    "        reference_pixel  = ff[4].header[\"CRPIX1\"]\n",
    "\n",
    "        galah_wave = ((np.arange(0,nr_pixels)--reference_pixel+1)*dispersion+start_wavelength)\n",
    "        galah_flux = np.array(ff[4].data)\n",
    "        galah_err  = np.array(ff[4].data * ff[1].data)\n",
    "        if ccd==1:            \n",
    "            for ax in [ax1,ax2,ax3,ax4]:\n",
    "                ax.plot(galah_wave,galah_flux,label='GALAH',c='C1')\n",
    "                ax.set_ylim(0,1.3)\n",
    "        else:\n",
    "            for ax in [ax1,ax2,ax3,ax4]:\n",
    "                ax.plot(galah_wave,galah_flux,c='C1',lw=1)\n",
    "            \n",
    "    ax1.set_xlim(6562.801-3, 6562.801+3)\n",
    "    ax2.set_xlim(li_line-3, li_line+3)\n",
    "    \n",
    "    be_line      = 4934.077#5270.81\n",
    "    hbeta_line   = 4861.363\n",
    "    halpha_line  = 6562.801\n",
    "    ax3.set_xlim(be_line-3, be_line+3) # Ba line 6496\n",
    "    ax4.set_xlim(4861-3, 4861+3) # hbeta line\n",
    "    ax4.axvline(hbeta_line, c='r', lw=1, label='H-beta') # hbeta line from https://classic.sdss.org/dr7/products/spectra/vacwavelength.php\n",
    "    ax1.axvline(halpha_line, c='r', lw=1, label='H-alpha') # halpha line\n",
    "    ax2.axvline(li_line, c='r', lw=1, label='Li')  # lithium line\n",
    "    ax3.axvline(be_line, c='r', lw=1, label='Be')  # lithium line\n",
    "    \n",
    "    for ax in [ax1,ax2,ax3,ax4]:\n",
    "        ax.legend()\n",
    "    \n",
    "    #ax5.axvline(be_line, c='k', lw=1)  # lithium line\n",
    "    #ax5.set_xlim(4800, be_line+10)\n",
    "    Li_val = rv_df.Li_val.values[0]\n",
    "    vbroad = rv_df.vbroad.values[0]\n",
    "    \n",
    "    title = 'P%s RG%s:    Li = %.1f    vbroad = %.1f' % (program, RG, Li_val, vbroad)\n",
    "\n",
    "    fig.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "for i,RG in enumerate(obj_dir_113.keys()):    \n",
    "    if i!= 0: continue\n",
    "    compare_to_galah(113,RG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfee9fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a116d98",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i,RG in enumerate(obj_dir_112.keys()):    \n",
    "    compare_to_galah(112,RG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00054641",
   "metadata": {},
   "outputs": [],
   "source": [
    "rv_df[(rv_df.program==113) & (rv_df.RG_id==5)].Li_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70441ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4713–4903, 5648–5873, 6478–6737, and 7585–7887"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e3d1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ab9bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,RG in enumerate(obj_dir_113.keys()):\n",
    "    pipeline(RG,obj_dir_113,113,close=False,savefig=False,savetxt=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2978ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checking(program, RG):\n",
    "    data = np.loadtxt('../files/normalized_spectra_txt/%s_%s.txt'%(program, RG))\n",
    "    wave, flux = data[:,0], data[:,1]\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.plot(wave, flux, lw=1)\n",
    "#     plt.xlim(6550,6570)\n",
    "#     plt.ylim(0.,1.5)\n",
    "checking(113, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d9bac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47eb5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,RG in enumerate(obj_dir_113.keys()):\n",
    "    pipeline(RG,obj_dir_113,113,close=False,savefig=False,savetxt=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195ff1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def paper_plot(RG, ax1, ax2, label1, label2, program=113, obj_dir = obj_dir_113):\n",
    "\n",
    "    from utils import PLOT_PARAMS\n",
    "    PLOT_PARAMS(LS=12,SIZE=12)\n",
    "    \n",
    "    wave, flux, ferr      = rv_correct(RG, obj_dir)\n",
    "    \n",
    "    # interpolate RV corrected spectra onto one grid\n",
    "    wave_grid, flux, ferr = interp_wave(wave, flux, ferr)\n",
    "    \n",
    "    # stack all target spectrum\n",
    "    stacked_flux     = stack(flux,plot=False)\n",
    "    \n",
    "    template         = load_template(RG, program)\n",
    "    \n",
    "    # interpolate the template onto target spectrum grid\n",
    "    temp_flux_interp = interp_template(wave_grid, template)  \n",
    "    \n",
    "    norm_flux = np.loadtxt('../files/normalized_spectra_txt/%s_%s.txt'%(program, RG))[:,1]\n",
    "    \n",
    "    #plt.figure(figsize=(6,5))\n",
    "    #ax1 = plt.subplot(211)\n",
    "\n",
    "    # mask out for plotting purposes\n",
    "    \n",
    "    mask             = (wave_grid>=6549) & (wave_grid<=6571)\n",
    "    wave_grid        = wave_grid[mask]\n",
    "    stacked_flux     = stacked_flux[mask]\n",
    "    norm_flux        = norm_flux[mask]\n",
    "    temp_flux_interp = temp_flux_interp[mask]\n",
    "    \n",
    "    ax1.plot(wave_grid,stacked_flux,color='grey',lw=0.5,alpha=0.8)\n",
    "    ax1.set_xlim(6550,6570)\n",
    "    \n",
    "    #ax2 = plt.subplot(212,sharex=ax1)\n",
    "    ax2.set_ylim(0.,1.2)\n",
    "    ax2.set_xlim(6550,6570)\n",
    "    ax2.plot(wave_grid, norm_flux, label='Red Giant',color='grey',lw=0.5,alpha=0.8)\n",
    "    ax2.plot(wave_grid, temp_flux_interp, label='Arcturus Template', color='darkred',lw=1)\n",
    "    ax2.legend(loc='lower left')\n",
    "        \n",
    "    ax1.set_ylabel('Flux')\n",
    "    ax2.set_ylabel('Normalized Flux')\n",
    "    ax2.set_xlabel(r'Wavelength [$\\AA$]')\n",
    "    \n",
    "    rv_df = pd.read_csv('comb_rvs.csv')\n",
    "    \n",
    "    Li_val = rv_df[(rv_df.program==program) & (rv_df.RG_id==RG)].Li_val.values[0]\n",
    "    vbr    = rv_df[(rv_df.program==program) & (rv_df.RG_id==RG)].vbroad.values[0]\n",
    "    text   = r'A(Li) = %.1f dex, $v_{\\rm broad}$ = %.1f km s$^{-1}$' % (Li_val,vbr)\n",
    "    \n",
    "    ax1.text(0.97, 0.05, s=label1, transform=ax1.transAxes, ha='right',va='bottom', fontsize=14)\n",
    "    ax2.text(0.97, 0.05, s=label2, transform=ax2.transAxes, ha='right',va='bottom', fontsize=14)\n",
    "    \n",
    "    ax1.text(0.03, 0.05, s=text, transform=ax1.transAxes, ha='left',va='bottom')\n",
    "    ax1.tick_params(axis='x', labelbottom=False)\n",
    "    \n",
    "    if RG == 19:\n",
    "        ax2.tick_params(axis='x', labelbottom=True)\n",
    "    else:\n",
    "        ax2.tick_params(axis='x', labelbottom=False)\n",
    "\n",
    "fig, (ax1, ax2, ax3, ax4, ax5, ax6) = plt.subplots(6, 1, figsize=(6,12))\n",
    "paper_plot(20, ax1, ax2, 'A', 'B')\n",
    "paper_plot(1,  ax3, ax4, 'C', 'D')\n",
    "paper_plot(19, ax5, ax6, 'E', 'F')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(hspace=0)\n",
    "# plt.savefig('../plots/example_spectra.png',bbox_inches='tight',dpi=200)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36ff673",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2961786d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i,RG in enumerate(obj_dir_113.keys()):\n",
    "    pipeline(RG,obj_dir_113,113,close=True,savefig=False,savetxt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec7bdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for RG in obj_dir_112.keys():\n",
    "    pipeline(RG,obj_dir_112,112,close=True,savefig=False,savetxt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e8f5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(w, f)\n",
    "plt.xlim(4200, 4500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc98cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c502671",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipeline(21,obj_dir_113,113,close=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd002729",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipeline(1,obj_dir_112,112,close=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abae336d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pipeline(6,obj_dir_112,112)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fa7e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b788e96d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ed1e9fa",
   "metadata": {},
   "source": [
    "## Practice with Catherine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cfeed9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file = files_113[11]\n",
    "hdul = fits.open(file)\n",
    "header     = hdul[0].header\n",
    "data       = hdul[1].data\n",
    "rv_val     =  header['HIERARCH ESO QC CCF RV']#header['HIERARCH ESO OCS OBJ RV'] #km/s\n",
    "wave, flux = data['WAVE_AIR'][0], data['FLUX    '][0]\n",
    "mask       = (wave > 3800)\n",
    "wave, flux = wave[mask], flux[mask]\n",
    "\n",
    "plt.figure(figsize=(12,3),dpi=150)\n",
    "plt.plot(wave, flux)\n",
    "plt.title(header['OBJECT'])\n",
    "#     plt.xlim(6550,6570)\n",
    "plt.xlim(4850, 4870)\n",
    "plt.ylim(0,0.6e-13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb2aa2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc62e69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
